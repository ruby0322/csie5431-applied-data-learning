{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6953115c740468a807a2ebd6202bcd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a7bbe21910f4db7ad18eaf478df683e",
              "IPY_MODEL_ee4e500405974589ad3a5dc7730f09bd",
              "IPY_MODEL_65970e82662a4fdba258ff4e1572f956"
            ],
            "layout": "IPY_MODEL_9403329896e34170a95d02c999a7799d"
          }
        },
        "4a7bbe21910f4db7ad18eaf478df683e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c56d22303aac4459a3d45638fd5b539e",
            "placeholder": "​",
            "style": "IPY_MODEL_19e188516bff40fc84f8054c5bd4f09b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ee4e500405974589ad3a5dc7730f09bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cf72a90ef0644148cc18c68b5754523",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_273440244e744f0f8043875777a0ef30",
            "value": 3
          }
        },
        "65970e82662a4fdba258ff4e1572f956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9fda4bbe2384ff290a4f603951c3146",
            "placeholder": "​",
            "style": "IPY_MODEL_e770d84b158e4af5a189447505395f38",
            "value": " 3/3 [00:04&lt;00:00,  1.22s/it]"
          }
        },
        "9403329896e34170a95d02c999a7799d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56d22303aac4459a3d45638fd5b539e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e188516bff40fc84f8054c5bd4f09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cf72a90ef0644148cc18c68b5754523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "273440244e744f0f8043875777a0ef30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9fda4bbe2384ff290a4f603951c3146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e770d84b158e4af5a189447505395f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e318cfd8c033407f9acd0bfb4735634c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b732a0fa8bb4941993fa6872980ccc2",
              "IPY_MODEL_6a8e6e51a8e14752ae9c10c949b5cdc3",
              "IPY_MODEL_081283381bf94c3588032c4f943b3ac5"
            ],
            "layout": "IPY_MODEL_90f2600e6072424dbbda59e69ca524c1"
          }
        },
        "5b732a0fa8bb4941993fa6872980ccc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de04d88f01f4bf5ae7d76e66d6009a3",
            "placeholder": "​",
            "style": "IPY_MODEL_d7980117ad8641be9bdee30ff1f66244",
            "value": "Map: 100%"
          }
        },
        "6a8e6e51a8e14752ae9c10c949b5cdc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df26c6a8e68a46b7a1672e90273b31b2",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d72cd9d0a3346768c50c259f70f6f6c",
            "value": 10000
          }
        },
        "081283381bf94c3588032c4f943b3ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c97a66cb504d4bd8a886d83c3b6647d2",
            "placeholder": "​",
            "style": "IPY_MODEL_2977e8f55d054354842848de7835a415",
            "value": " 10000/10000 [00:04&lt;00:00, 2354.23 examples/s]"
          }
        },
        "90f2600e6072424dbbda59e69ca524c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de04d88f01f4bf5ae7d76e66d6009a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7980117ad8641be9bdee30ff1f66244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df26c6a8e68a46b7a1672e90273b31b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d72cd9d0a3346768c50c259f70f6f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c97a66cb504d4bd8a886d83c3b6647d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2977e8f55d054354842848de7835a415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2bb6828e14c41e2b3c7c98bdda32df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee1a57e8f46d4d6293f0d9a9beed6c12",
              "IPY_MODEL_58afc1d0099d475d8ca975296d103d9b",
              "IPY_MODEL_cc517be727cd456ba729abc7effb9e4a"
            ],
            "layout": "IPY_MODEL_86301b999fd94f30a9933ce73d83ca0f"
          }
        },
        "ee1a57e8f46d4d6293f0d9a9beed6c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d1f4c8aeaeb49a4965bc54798fb301c",
            "placeholder": "​",
            "style": "IPY_MODEL_5ff9ee768b814ac9a020b05e34b204e5",
            "value": "Map: 100%"
          }
        },
        "58afc1d0099d475d8ca975296d103d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_990ae092c16e489b9b4dc9d26a9a68cf",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc187beb461f4bdcbadac273b6b58e5b",
            "value": 20
          }
        },
        "cc517be727cd456ba729abc7effb9e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cadff8c4fd047a0954299ac7587ef72",
            "placeholder": "​",
            "style": "IPY_MODEL_11ec5f74868445db970ea1d4c353afcd",
            "value": " 20/20 [00:00&lt;00:00, 684.16 examples/s]"
          }
        },
        "86301b999fd94f30a9933ce73d83ca0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1f4c8aeaeb49a4965bc54798fb301c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff9ee768b814ac9a020b05e34b204e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "990ae092c16e489b9b4dc9d26a9a68cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc187beb461f4bdcbadac273b6b58e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cadff8c4fd047a0954299ac7587ef72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11ec5f74868445db970ea1d4c353afcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Deps"
      ],
      "metadata": {
        "id": "dMdS-rFCrEkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.4.1 transformers==4.45.1 bitsandbytes==0.44.1 peft==0.13.0 datasets trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1TM_fFPqZwe",
        "outputId": "5257238f-7441-4e04-9370-770b214ceeed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: transformers==4.45.1 in /usr/local/lib/python3.10/dist-packages (4.45.1)\n",
            "Requirement already satisfied: bitsandbytes==0.44.1 in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
            "Requirement already satisfied: peft==0.13.0 in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.13.0) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.0) (0.34.2)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.6.77)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (2024.8.30)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.9.3)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages and Data"
      ],
      "metadata": {
        "id": "_Tg39kPcrIap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    TrainerCallback,\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    prepare_model_for_kbit_training,\n",
        "    get_peft_model,\n",
        ")\n",
        "from trl import SFTTrainer\n",
        "from tqdm import tqdm\n",
        "import datasets\n",
        "import os\n",
        "import json\n",
        "from typing import Dict"
      ],
      "metadata": {
        "id": "ggbmKhXtqTgt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clear GPU memory\n",
        "def clear_gpu_memory():\n",
        "    # Delete any large variables (replace 'variable' with your variable names if applicable)\n",
        "    # del variable_name  # Uncomment and replace variable_name with any large variable you want to delete\n",
        "\n",
        "    # Clear PyTorch's cache\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Optionally, you can print the GPU memory to confirm clearance\n",
        "    print(f\"Memory Allocated: {torch.cuda.memory_allocated()} bytes\")\n",
        "    print(f\"Memory Reserved: {torch.cuda.memory_reserved()} bytes\")\n",
        "\n",
        "# Usage\n",
        "clear_gpu_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NR0ycOlLlPb",
        "outputId": "93e7038c-95e8-409a-b30c-69ef6eba3100"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory Allocated: 0 bytes\n",
            "Memory Reserved: 0 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./csie5431-applied-data-learning\n",
        "!git clone https://github.com/ruby0322/csie5431-applied-data-learning.git\n",
        "!mv ./csie5431-applied-data-learning/hw3/preprocess.py ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzH6DM7orPbD",
        "outputId": "a1265339-0add-4972-b685-b2b82ecf8626"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'csie5431-applied-data-learning'...\n",
            "remote: Enumerating objects: 346, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 346 (delta 46), reused 121 (delta 31), pack-reused 207 (from 1)\u001b[K\n",
            "Receiving objects: 100% (346/346), 4.23 MiB | 16.98 MiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1X04jwetkzUnlAtX0W4exMQU1x1Us-yfc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TziH_24sCp2",
        "outputId": "1381e97a-4b5e-4cd4-f696-51d748e01fd3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1X04jwetkzUnlAtX0W4exMQU1x1Us-yfc\n",
            "To: /content/hw3.zip\n",
            "\r  0% 0.00/1.26M [00:00<?, ?B/s]\r100% 1.26M/1.26M [00:00<00:00, 103MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if the `./hw3` directory already exists\n",
        "if not os.path.exists('./hw3'):\n",
        "    # Unzip the file if `./hw3` does not exist\n",
        "    !unzip hw3.zip\n",
        "    # Move the data directory\n",
        "    !mv ./hw3/data ./data\n",
        "else:\n",
        "    print(\"Directory './hw3' already exists. Skipping unzip.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwgQZVKLsEne",
        "outputId": "d8f15476-5db2-47ec-d7e7-987d84f89d3f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory './hw3' already exists. Skipping unzip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocess.py ./data/train.json ./data/train_preprocessed.json\n",
        "!python preprocess.py ./data/public_test.json ./data/public_test_preprocessed.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-ZtTUYMsVuj",
        "outputId": "1af45a2d-bfa3-4384-93f4-108ea11eb217"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been saved to ./data/train_preprocessed.json\n",
            "Data has been saved to ./data/public_test_preprocessed.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessed_train_df = pd.read_json('./data/train_preprocessed.json')\n",
        "preprocessed_train_df = pd.read_json('./data/train.json')\n",
        "preprocessed_train_df = preprocessed_train_df[preprocessed_train_df['task'] != '']\n",
        "# preprocessed_test_df = pd.read_json('./data/public_test_preprocessed.json')\n",
        "preprocessed_test_df = pd.read_json('./data/public_test.json')"
      ],
      "metadata": {
        "id": "kgqhJHh6sYjI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "tG19X8tsrN9T",
        "outputId": "f8c0aad1-1187-429e-c2f8-42b3144340e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        id  \\\n",
              "0     db63fb72-e211-4596-94a4-69617706f7ef   \n",
              "1     a48b0e8f-dc7a-4130-acc6-a91cc4a81bd1   \n",
              "2     f98882de-6962-46cf-a8f0-5d534eddda3a   \n",
              "3     c491b5f1-fe54-4276-8dd2-cbc7a8d0f3c3   \n",
              "4     bc8d68a3-cfe2-42ee-9d99-415380975642   \n",
              "...                                    ...   \n",
              "9995  98e706d5-0a33-4b56-9849-fe970f7dfcb2   \n",
              "9996  9f38308a-63b4-46fb-9262-e5442ab23a6b   \n",
              "9997  3d714828-0cce-4806-8af0-11fd863446ae   \n",
              "9998  df77d459-7afe-4b50-81f9-fba03ee94ee2   \n",
              "9999  6179862a-fb53-408a-a4ad-cfbc9065171e   \n",
              "\n",
              "                                            instruction  \\\n",
              "0                雅裏惱怒地說： 從前在福山田獵時，你誣陷獵官，現在又說這種話。翻譯成文言文：   \n",
              "1                                  沒過十天，鮑泉果然被拘捕。翻譯成文言文：   \n",
              "2                         辛未，命吳堅為左丞相兼樞密使，常楙參知政事。翻譯成白話文：   \n",
              "3     十八年，奚、契丹侵犯邊界，以皇上為河北道元帥，信安王為副，率禦史大夫李朝隱、京兆尹裴亻由先等...   \n",
              "4                       正月，甲子朔，鼕至，太後享通天宮；赦天下，改元。翻譯成白話文：   \n",
              "...                                                 ...   \n",
              "9995                        所派的官員還未到哈密，脫脫便得暴病去世。翻譯成文言文：   \n",
              "9996                   李聽命令士兵收起武器在野外駐紮，魏州人纔安定下來。翻譯成文言文：   \n",
              "9997                 因此忠貞的臣子，並非不想竭盡忠誠，竭盡忠誠實在太難瞭。翻譯成文言文：   \n",
              "9998                        祿山構逆，承嗣與張忠誌等為前鋒，陷河洛。翻譯成白話文：   \n",
              "9999                  五年春正月丙午，齊獻武王在晉陽逝世，秘密不公布喪事。翻譯成文言文：   \n",
              "\n",
              "                                                 output    task  \n",
              "0                               雅裏怒曰： 昔畋於福山，卿誣獵官，今復有此言。  翻譯成文言文  \n",
              "1                                             後未旬，果見囚執。  翻譯成文言文  \n",
              "2                              初五，命令吳堅為左承相兼樞密使，常增為參知政事。  翻譯成白話文  \n",
              "3     十八年，奚、契丹犯塞，以上為河北道元帥，信安王禕為副，帥禦史大夫李朝隱、京兆尹裴伷先等八總管...  翻譯成文言文  \n",
              "4                     聖曆元年正月，甲子朔，鼕至，太後在通天宮祭祀；大赦天下，更改年號。  翻譯成白話文  \n",
              "...                                                 ...     ...  \n",
              "9995                                        未至，而脫脫以暴疾卒。  翻譯成文言文  \n",
              "9996                                      聽敕士櫜兵野次，魏人乃安。  翻譯成文言文  \n",
              "9997                              故忠貞之臣，非不欲竭誠。竭誠者，乃是極難。  翻譯成文言文  \n",
              "9998                           安祿山叛亂，田承嗣和張忠誌等擔任先鋒，攻陷河洛。  翻譯成白話文  \n",
              "9999                             五年春正月丙午，齊獻武王薨於晉陽，秘不發喪。  翻譯成文言文  \n",
              "\n",
              "[10000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96599d47-eff7-4bc0-b707-9048dc90310d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>instruction</th>\n",
              "      <th>output</th>\n",
              "      <th>task</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>db63fb72-e211-4596-94a4-69617706f7ef</td>\n",
              "      <td>雅裏惱怒地說： 從前在福山田獵時，你誣陷獵官，現在又說這種話。翻譯成文言文：</td>\n",
              "      <td>雅裏怒曰： 昔畋於福山，卿誣獵官，今復有此言。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a48b0e8f-dc7a-4130-acc6-a91cc4a81bd1</td>\n",
              "      <td>沒過十天，鮑泉果然被拘捕。翻譯成文言文：</td>\n",
              "      <td>後未旬，果見囚執。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>f98882de-6962-46cf-a8f0-5d534eddda3a</td>\n",
              "      <td>辛未，命吳堅為左丞相兼樞密使，常楙參知政事。翻譯成白話文：</td>\n",
              "      <td>初五，命令吳堅為左承相兼樞密使，常增為參知政事。</td>\n",
              "      <td>翻譯成白話文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c491b5f1-fe54-4276-8dd2-cbc7a8d0f3c3</td>\n",
              "      <td>十八年，奚、契丹侵犯邊界，以皇上為河北道元帥，信安王為副，率禦史大夫李朝隱、京兆尹裴亻由先等...</td>\n",
              "      <td>十八年，奚、契丹犯塞，以上為河北道元帥，信安王禕為副，帥禦史大夫李朝隱、京兆尹裴伷先等八總管...</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bc8d68a3-cfe2-42ee-9d99-415380975642</td>\n",
              "      <td>正月，甲子朔，鼕至，太後享通天宮；赦天下，改元。翻譯成白話文：</td>\n",
              "      <td>聖曆元年正月，甲子朔，鼕至，太後在通天宮祭祀；大赦天下，更改年號。</td>\n",
              "      <td>翻譯成白話文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>98e706d5-0a33-4b56-9849-fe970f7dfcb2</td>\n",
              "      <td>所派的官員還未到哈密，脫脫便得暴病去世。翻譯成文言文：</td>\n",
              "      <td>未至，而脫脫以暴疾卒。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9f38308a-63b4-46fb-9262-e5442ab23a6b</td>\n",
              "      <td>李聽命令士兵收起武器在野外駐紮，魏州人纔安定下來。翻譯成文言文：</td>\n",
              "      <td>聽敕士櫜兵野次，魏人乃安。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>3d714828-0cce-4806-8af0-11fd863446ae</td>\n",
              "      <td>因此忠貞的臣子，並非不想竭盡忠誠，竭盡忠誠實在太難瞭。翻譯成文言文：</td>\n",
              "      <td>故忠貞之臣，非不欲竭誠。竭誠者，乃是極難。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>df77d459-7afe-4b50-81f9-fba03ee94ee2</td>\n",
              "      <td>祿山構逆，承嗣與張忠誌等為前鋒，陷河洛。翻譯成白話文：</td>\n",
              "      <td>安祿山叛亂，田承嗣和張忠誌等擔任先鋒，攻陷河洛。</td>\n",
              "      <td>翻譯成白話文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>6179862a-fb53-408a-a4ad-cfbc9065171e</td>\n",
              "      <td>五年春正月丙午，齊獻武王在晉陽逝世，秘密不公布喪事。翻譯成文言文：</td>\n",
              "      <td>五年春正月丙午，齊獻武王薨於晉陽，秘不發喪。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96599d47-eff7-4bc0-b707-9048dc90310d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96599d47-eff7-4bc0-b707-9048dc90310d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96599d47-eff7-4bc0-b707-9048dc90310d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a682dae9-add6-4ec4-b44d-b98b580e3f77\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a682dae9-add6-4ec4-b44d-b98b580e3f77')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a682dae9-add6-4ec4-b44d-b98b580e3f77 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6d108207-e123-4afb-90bb-aa7f0267ecee\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('preprocessed_train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6d108207-e123-4afb-90bb-aa7f0267ecee button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('preprocessed_train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "preprocessed_train_df",
              "summary": "{\n  \"name\": \"preprocessed_train_df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"49e08b00-1028-44c8-aef8-fe7e6e8f37e6\",\n          \"41af2a9c-a605-4b69-881a-f53fbc5b1212\",\n          \"27a9cf60-a7fb-4662-8d7f-54bdc95bb86d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9914,\n        \"samples\": [\n          \"\\u90a3\\u98c4\\u6eff\\u82b3\\u9999\\u7684\\u6c34\\u5cb8\\u908a\\uff0c\\u4eba\\u5011\\u768b\\u8d77\\u92e4\\u982d\\u5c0d\\u6297\\u5f37\\u79e6\\u3002\\u6211\\u53c8\\u8def\\u904e\\u5433\\u5730\\u5230\\u9054\\u8d8a\\u5883\\uff0c\\u518d\\u53d6\\u9053\\u6d77\\u8def\\u901a\\u56ae\\u95a9\\u90e1\\u3002\\u7ffb\\u8b6f\\u6210\\u6587\\u8a00\\u6587\\uff1a\",\n          \"\\u6cc1\\u4e14\\u79e6\\u4eba\\u6d1e\\u7684\\u6c34\\uff0c\\u4e5f\\u66fe\\u6df9\\u5230\\u6211\\u7684\\u819d\\u84cb\\u3001\\u6d78\\u6fd5\\u904e\\u5927\\u817f\\uff0c\\u90fd\\u6eab\\u6696\\u4e0d\\u89ba\\u5f97\\u5bd2\\u51b7\\uff0c\\u800c\\u6b64\\u6d1e\\u4e2d\\u7684\\u6c34\\u5bd2\\u51b7\\uff0c\\u8207\\u6eaa\\u6f97\\u4e2d\\u7684\\u6c92\\u6709\\u5dee\\u5f46\\u3002\\u7ffb\\u8b6f\\u6210\\u6587\\u8a00\\u6587\\uff1a\",\n          \"\\u9149\\u8fce\\u6230\\uff0c\\u9032\\u81f3\\u9e79\\u967d\\u5317\\u6fc1\\u6996\\uff0c\\u570d\\u50de\\u53f8\\u7a7a\\u9577\\u6d1b\\u738b\\u7e46\\u8001\\u751f\\uff0c\\u95a4\\u6230\\uff0c\\u53c8\\u5927\\u7834\\u4e4b\\uff0c\\u8001\\u751f\\u8d70\\u9084\\u9577\\u5b89\\u3002\\u7ffb\\u8b6f\\u6210\\u767d\\u8a71\\u6587\\uff1a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9993,\n        \"samples\": [\n          \"\\u4e94\\u6708\\uff0c\\u5149\\u6d5a\\u653b\\u71df\\u5dde\\uff0c\\u523a\\u53f2\\u694a\\u9756\\u964d\\u3002\",\n          \"\\u76f4\\u5f8c\\u5f35\\u9f4a\\u65ac\\u9996\\u9001\\u6881\\u738b\\u3002\",\n          \"\\u904e\\u53bb\\uff0c\\u95a9\\u4e3b\\u738b\\u66e6\\u4f8d\\u5949\\u5eb7\\u5b97\\u738b\\u6636\\u5bb4\\u6703\\uff0c\\u9047\\u4e0a\\u65b0\\u7f85\\u570b\\u9032\\u737b\\u5bf6\\u528d\\uff0c\\u5eb7\\u5b97\\u8209\\u8d77\\u528d\\u554f\\u540c\\u5e73\\u7ae0\\u4e8b\\u738b\\u8aaa\\uff1a \\u9019\\u500b\\u53ef\\u4ee5\\u4e7e\\u4ec0\\u9ebc\\u7528\\uff1f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"task\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\u7ffb\\u8b6f\\u6210\\u767d\\u8a71\\u6587\",\n          \"\\u7ffb\\u8b6f\\u6210\\u6587\\u8a00\\u6587\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_test_df.iloc[6]['instruction']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "shW0qG_gkZgN",
        "outputId": "4876a8cb-ecdd-4932-ebe3-caafb1582462"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'從唐末幽、薊二州割據以來，戍守的軍隊廢置散失，契丹因而得以齣來攻陷平、營二州，而幽、薊二州的人每年深受契丹侵犯掠奪之苦。翻譯成文言文：'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_test_df = preprocessed_test_df.iloc[:20]\n",
        "preprocessed_test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GXxitj2GspBD",
        "outputId": "97ce1a1f-e15d-4566-d4be-4aa9900be287"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      id  \\\n",
              "0   2fb7d211-978f-41c8-a3ab-e51d9df06280   \n",
              "1   07f75449-94b9-4c3b-a525-e62cdbf85382   \n",
              "2   7b7ead70-1353-433f-a59f-7704594cce59   \n",
              "3   b8adf597-edb9-46d4-a1a6-074ce9724f07   \n",
              "4   87945a20-f869-4be9-b586-f5ce20ddd78b   \n",
              "5   243f36a1-edbf-4f64-b7e8-4b7414ced101   \n",
              "6   d11ff6fb-4ff7-44b5-b08a-1dfa98249ec5   \n",
              "7   d8d4baf4-c634-453e-83a9-08bb113e6547   \n",
              "8   72335b5a-ad07-4255-8a9a-0469ee1dd9f7   \n",
              "9   d9de64d9-5c6c-4bfd-8e9c-136e43974319   \n",
              "10  c196d07c-8772-4209-8259-55acb98fa36c   \n",
              "11  a11c6867-8e71-406f-8c14-94b41d473fbe   \n",
              "12  e0614eb6-e140-48da-a7f3-699a3eb77b66   \n",
              "13  e8fb3265-f413-4f01-8c92-d88c882f88b7   \n",
              "14  1ac96064-6d7f-46ae-babb-e188c014d9cb   \n",
              "15  e5cd0e28-f412-41ae-a4ff-1d87a0652ffb   \n",
              "16  6ce36df7-0a77-47c5-aee9-0b87f7995605   \n",
              "17  d3e772e6-7495-4da4-8a59-52a5dafd4119   \n",
              "18  badf11dd-a376-413c-aad1-24d1b36f0cc7   \n",
              "19  6adf911d-b05f-4a0e-96a1-afd54c05de51   \n",
              "\n",
              "                                          instruction  \\\n",
              "0            於是，廢帝讓瀋慶之的堂侄、直將軍瀋攸之賜瀋慶之毒藥，命瀋慶之自殺。翻譯成文言文：   \n",
              "1                          靈鑒忽臨，忻歡交集，乃迴燈拂席以延之。翻譯成白話文：   \n",
              "2                  希望您以後留意，不要再齣這樣的事，你的小女兒病就會好。翻譯成文言文：   \n",
              "3                    第二年召迴朝廷，改任著作佐郎，直史館，改任左拾遺。翻譯成文言文：   \n",
              "4                     中宗與庶人嘗因正月十五日夜幸其第，賜賚不可勝數。翻譯成白話文：   \n",
              "5                                   硃全忠聽後哈哈大笑。翻譯成文言文：   \n",
              "6   從唐末幽、薊二州割據以來，戍守的軍隊廢置散失，契丹因而得以齣來攻陷平、營二州，而幽、薊二州的...   \n",
              "7   建武帝蕭鸞繼位做皇帝，沿襲陳舊的一套做法，當時流行風氣不好文學，輔臣宰相沒有學識，學校雖然設...   \n",
              "8     契丹主以陽城之戰為彥卿所敗，詰之。彥卿曰： 臣當時惟知為晉主竭力，今日死生惟命。翻譯成白話文：   \n",
              "9   秦領是都人，從江夏都尉升任南陽太守，上任時經過宜城城內，看見一傢朝東的房子，他停車觀看，說：...   \n",
              "10                        泰始四年正月丁亥日，皇帝親自耕種責任田。翻譯成文言文：   \n",
              "11                                  能服信政，此謂正紀。翻譯成白話文：   \n",
              "12     但是，祭祀中的登堂分食祭品、嚮屍獻酒、飲奠解，這些事一定要由國君的嫡長子來做。翻譯成文言文：   \n",
              "13                               孝文貞皇後林氏，是平原人。翻譯成文言文：   \n",
              "14         宇文述死後，煬帝懷念他，起用宇文化及任右屯衛將軍，宇文智及任將作少監。翻譯成文言文：   \n",
              "15                               晉荀偃伐齊，不卒事，而還。翻譯成白話文：   \n",
              "16                          二十二日，商州尚可孤在藍田攻破賊兵。翻譯成文言文：   \n",
              "17                 派侍禦史裴茂訊問詔令所關押的犯人，寬宥輕罪在押的犯人。翻譯成文言文：   \n",
              "18               四年，太祖攻下東平，硃友裕改任天平軍留後，加封為檢校司徒。翻譯成文言文：   \n",
              "19  等脩行師到達，腹背攻擊他，脩行師大敗，因而乞求投降，陸子隆同意他投降，將他送於京師。翻譯成文言文：   \n",
              "\n",
              "                                               output    task  \n",
              "0                                帝乃使慶之從父兄子直閣將軍攸之賜慶之藥。  翻譯成文言文  \n",
              "1              答案：靈仙忽然光臨，趙旭歡欣交集，於是他就把燈點亮，拂拭乾淨床席來延請仙女。  翻譯成白話文  \n",
              "2                                       以後幸長官留意，勿令如此。  翻譯成文言文  \n",
              "3                                明年召還，改著作佐郎，直史館，改左拾遺。  翻譯成文言文  \n",
              "4            答案：唐中宗與韋庶人曾經在正月十五日夜到韋安石的宅第，並賜賞給他不可勝數的財物。  翻譯成白話文  \n",
              "5                                               全忠大笑。  翻譯成文言文  \n",
              "6                 自唐末幽、薊割據，戍兵廢散，契丹因得齣陷平、營，而幽、薊之人歲苦寇鈔。  翻譯成文言文  \n",
              "7    建武繼立，因循舊緒，時不好文，輔相無術，學校雖設，前軌難追。劉瓛承馬、鄭之後，一時學徒以為師範。  翻譯成文言文  \n",
              "8   答案：契丹主因陽城之戰被符彥卿打敗，追問符彥卿，彥卿說： 臣當時隻知為晉主竭盡全力，今日死生...  翻譯成白話文  \n",
              "9        頡，鄀人也，以江夏都尉齣為南陽太守。徑宜城中，見一傢東嚮，頡住車視之，曰：此居處可作塚。  翻譯成文言文  \n",
              "10                                      四年正月丁亥，帝親耕藉田。  翻譯成文言文  \n",
              "11                                     能守信於民，這叫作端正綱紀。  翻譯成白話文  \n",
              "12                           其在宗廟之中，則如外朝之位。宗人授事，以爵以官。  翻譯成文言文  \n",
              "13                                      孝文貞皇後林氏，平原人也。  翻譯成文言文  \n",
              "14                          述薨後，煬帝追憶之，起化及為右屯衛將軍，將作少監。  翻譯成文言文  \n",
              "15                              晉國的荀偃進攻齊國，沒有結束戰事就迴來瞭。  翻譯成白話文  \n",
              "16                                     壬辰，商州尚可孤破賊於藍田。  翻譯成文言文  \n",
              "17                                     遣侍禦史裴茂訊詔獄，原輕係。  翻譯成文言文  \n",
              "18                             四年，太祖下東平，改天平軍留後，加檢校司徒。  翻譯成文言文  \n",
              "19                      及行師至，腹背擊之，行師大敗，因乞降，子隆許之，送於京師。  翻譯成文言文  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3df05880-c05e-4aa3-99ec-81cfdbd9bc2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>instruction</th>\n",
              "      <th>output</th>\n",
              "      <th>task</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2fb7d211-978f-41c8-a3ab-e51d9df06280</td>\n",
              "      <td>於是，廢帝讓瀋慶之的堂侄、直將軍瀋攸之賜瀋慶之毒藥，命瀋慶之自殺。翻譯成文言文：</td>\n",
              "      <td>帝乃使慶之從父兄子直閣將軍攸之賜慶之藥。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>07f75449-94b9-4c3b-a525-e62cdbf85382</td>\n",
              "      <td>靈鑒忽臨，忻歡交集，乃迴燈拂席以延之。翻譯成白話文：</td>\n",
              "      <td>答案：靈仙忽然光臨，趙旭歡欣交集，於是他就把燈點亮，拂拭乾淨床席來延請仙女。</td>\n",
              "      <td>翻譯成白話文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7b7ead70-1353-433f-a59f-7704594cce59</td>\n",
              "      <td>希望您以後留意，不要再齣這樣的事，你的小女兒病就會好。翻譯成文言文：</td>\n",
              "      <td>以後幸長官留意，勿令如此。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b8adf597-edb9-46d4-a1a6-074ce9724f07</td>\n",
              "      <td>第二年召迴朝廷，改任著作佐郎，直史館，改任左拾遺。翻譯成文言文：</td>\n",
              "      <td>明年召還，改著作佐郎，直史館，改左拾遺。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>87945a20-f869-4be9-b586-f5ce20ddd78b</td>\n",
              "      <td>中宗與庶人嘗因正月十五日夜幸其第，賜賚不可勝數。翻譯成白話文：</td>\n",
              "      <td>答案：唐中宗與韋庶人曾經在正月十五日夜到韋安石的宅第，並賜賞給他不可勝數的財物。</td>\n",
              "      <td>翻譯成白話文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>243f36a1-edbf-4f64-b7e8-4b7414ced101</td>\n",
              "      <td>硃全忠聽後哈哈大笑。翻譯成文言文：</td>\n",
              "      <td>全忠大笑。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>d11ff6fb-4ff7-44b5-b08a-1dfa98249ec5</td>\n",
              "      <td>從唐末幽、薊二州割據以來，戍守的軍隊廢置散失，契丹因而得以齣來攻陷平、營二州，而幽、薊二州的...</td>\n",
              "      <td>自唐末幽、薊割據，戍兵廢散，契丹因得齣陷平、營，而幽、薊之人歲苦寇鈔。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>d8d4baf4-c634-453e-83a9-08bb113e6547</td>\n",
              "      <td>建武帝蕭鸞繼位做皇帝，沿襲陳舊的一套做法，當時流行風氣不好文學，輔臣宰相沒有學識，學校雖然設...</td>\n",
              "      <td>建武繼立，因循舊緒，時不好文，輔相無術，學校雖設，前軌難追。劉瓛承馬、鄭之後，一時學徒以為師範。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>72335b5a-ad07-4255-8a9a-0469ee1dd9f7</td>\n",
              "      <td>契丹主以陽城之戰為彥卿所敗，詰之。彥卿曰： 臣當時惟知為晉主竭力，今日死生惟命。翻譯成白話文：</td>\n",
              "      <td>答案：契丹主因陽城之戰被符彥卿打敗，追問符彥卿，彥卿說： 臣當時隻知為晉主竭盡全力，今日死生...</td>\n",
              "      <td>翻譯成白話文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>d9de64d9-5c6c-4bfd-8e9c-136e43974319</td>\n",
              "      <td>秦領是都人，從江夏都尉升任南陽太守，上任時經過宜城城內，看見一傢朝東的房子，他停車觀看，說：...</td>\n",
              "      <td>頡，鄀人也，以江夏都尉齣為南陽太守。徑宜城中，見一傢東嚮，頡住車視之，曰：此居處可作塚。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>c196d07c-8772-4209-8259-55acb98fa36c</td>\n",
              "      <td>泰始四年正月丁亥日，皇帝親自耕種責任田。翻譯成文言文：</td>\n",
              "      <td>四年正月丁亥，帝親耕藉田。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>a11c6867-8e71-406f-8c14-94b41d473fbe</td>\n",
              "      <td>能服信政，此謂正紀。翻譯成白話文：</td>\n",
              "      <td>能守信於民，這叫作端正綱紀。</td>\n",
              "      <td>翻譯成白話文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>e0614eb6-e140-48da-a7f3-699a3eb77b66</td>\n",
              "      <td>但是，祭祀中的登堂分食祭品、嚮屍獻酒、飲奠解，這些事一定要由國君的嫡長子來做。翻譯成文言文：</td>\n",
              "      <td>其在宗廟之中，則如外朝之位。宗人授事，以爵以官。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>e8fb3265-f413-4f01-8c92-d88c882f88b7</td>\n",
              "      <td>孝文貞皇後林氏，是平原人。翻譯成文言文：</td>\n",
              "      <td>孝文貞皇後林氏，平原人也。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1ac96064-6d7f-46ae-babb-e188c014d9cb</td>\n",
              "      <td>宇文述死後，煬帝懷念他，起用宇文化及任右屯衛將軍，宇文智及任將作少監。翻譯成文言文：</td>\n",
              "      <td>述薨後，煬帝追憶之，起化及為右屯衛將軍，將作少監。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>e5cd0e28-f412-41ae-a4ff-1d87a0652ffb</td>\n",
              "      <td>晉荀偃伐齊，不卒事，而還。翻譯成白話文：</td>\n",
              "      <td>晉國的荀偃進攻齊國，沒有結束戰事就迴來瞭。</td>\n",
              "      <td>翻譯成白話文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>6ce36df7-0a77-47c5-aee9-0b87f7995605</td>\n",
              "      <td>二十二日，商州尚可孤在藍田攻破賊兵。翻譯成文言文：</td>\n",
              "      <td>壬辰，商州尚可孤破賊於藍田。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>d3e772e6-7495-4da4-8a59-52a5dafd4119</td>\n",
              "      <td>派侍禦史裴茂訊問詔令所關押的犯人，寬宥輕罪在押的犯人。翻譯成文言文：</td>\n",
              "      <td>遣侍禦史裴茂訊詔獄，原輕係。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>badf11dd-a376-413c-aad1-24d1b36f0cc7</td>\n",
              "      <td>四年，太祖攻下東平，硃友裕改任天平軍留後，加封為檢校司徒。翻譯成文言文：</td>\n",
              "      <td>四年，太祖下東平，改天平軍留後，加檢校司徒。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6adf911d-b05f-4a0e-96a1-afd54c05de51</td>\n",
              "      <td>等脩行師到達，腹背攻擊他，脩行師大敗，因而乞求投降，陸子隆同意他投降，將他送於京師。翻譯成文言文：</td>\n",
              "      <td>及行師至，腹背擊之，行師大敗，因乞降，子隆許之，送於京師。</td>\n",
              "      <td>翻譯成文言文</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3df05880-c05e-4aa3-99ec-81cfdbd9bc2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3df05880-c05e-4aa3-99ec-81cfdbd9bc2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3df05880-c05e-4aa3-99ec-81cfdbd9bc2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9641f164-fbd9-4f2e-af13-cc78c234acdd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9641f164-fbd9-4f2e-af13-cc78c234acdd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9641f164-fbd9-4f2e-af13-cc78c234acdd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e8c6d43f-fda2-47f8-8f25-b662577b38e7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('preprocessed_test_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e8c6d43f-fda2-47f8-8f25-b662577b38e7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('preprocessed_test_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "preprocessed_test_df",
              "summary": "{\n  \"name\": \"preprocessed_test_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"2fb7d211-978f-41c8-a3ab-e51d9df06280\",\n          \"d3e772e6-7495-4da4-8a59-52a5dafd4119\",\n          \"e5cd0e28-f412-41ae-a4ff-1d87a0652ffb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"\\u65bc\\u662f\\uff0c\\u5ee2\\u5e1d\\u8b93\\u700b\\u6176\\u4e4b\\u7684\\u5802\\u4f84\\u3001\\u76f4\\u5c07\\u8ecd\\u700b\\u6538\\u4e4b\\u8cdc\\u700b\\u6176\\u4e4b\\u6bd2\\u85e5\\uff0c\\u547d\\u700b\\u6176\\u4e4b\\u81ea\\u6bba\\u3002\\u7ffb\\u8b6f\\u6210\\u6587\\u8a00\\u6587\\uff1a\",\n          \"\\u6d3e\\u4f8d\\u79a6\\u53f2\\u88f4\\u8302\\u8a0a\\u554f\\u8a54\\u4ee4\\u6240\\u95dc\\u62bc\\u7684\\u72af\\u4eba\\uff0c\\u5bec\\u5ba5\\u8f15\\u7f6a\\u5728\\u62bc\\u7684\\u72af\\u4eba\\u3002\\u7ffb\\u8b6f\\u6210\\u6587\\u8a00\\u6587\\uff1a\",\n          \"\\u6649\\u8340\\u5043\\u4f10\\u9f4a\\uff0c\\u4e0d\\u5352\\u4e8b\\uff0c\\u800c\\u9084\\u3002\\u7ffb\\u8b6f\\u6210\\u767d\\u8a71\\u6587\\uff1a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"\\u5e1d\\u4e43\\u4f7f\\u6176\\u4e4b\\u5f9e\\u7236\\u5144\\u5b50\\u76f4\\u95a3\\u5c07\\u8ecd\\u6538\\u4e4b\\u8cdc\\u6176\\u4e4b\\u85e5\\u3002\",\n          \"\\u9063\\u4f8d\\u79a6\\u53f2\\u88f4\\u8302\\u8a0a\\u8a54\\u7344\\uff0c\\u539f\\u8f15\\u4fc2\\u3002\",\n          \"\\u6649\\u570b\\u7684\\u8340\\u5043\\u9032\\u653b\\u9f4a\\u570b\\uff0c\\u6c92\\u6709\\u7d50\\u675f\\u6230\\u4e8b\\u5c31\\u8ff4\\u4f86\\u77ad\\u3002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"task\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\u7ffb\\u8b6f\\u6210\\u767d\\u8a71\\u6587\",\n          \"\\u7ffb\\u8b6f\\u6210\\u6587\\u8a00\\u6587\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.Dataset.from_pandas(preprocessed_train_df)\n",
        "test_dataset = datasets.Dataset.from_pandas(preprocessed_test_df)"
      ],
      "metadata": {
        "id": "EBTQX7aSsy7r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Util Functions"
      ],
      "metadata": {
        "id": "GFWkJvrxs2g0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LENGTH = 512"
      ],
      "metadata": {
        "id": "kiL_4nogEFL0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"0\"\n",
        "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"8.0+PTX\"\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"CUDNN_BENCHMARK\"] = \"0\"\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
      ],
      "metadata": {
        "id": "iehKZcTOJ3Gb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bnb_config() -> BitsAndBytesConfig:\n",
        "    \"\"\"Configure quantization for QLoRA 4-bit training\"\"\"\n",
        "    return BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_fp32_cpu_offload=True  # Enable CPU offloading here\n",
        "    )\n",
        "\n",
        "def get_prompt(instruction: str) -> str:\n",
        "    \"\"\"Format the instruction into a prompt template\"\"\"\n",
        "    return f\"你是一位精通古今中文的翻譯專家。只回覆翻譯結果，不可有多餘說明或解釋。\\nUSER: {instruction}\\nASSISTANT:\"\n",
        "\n",
        "def calculate_perplexity(model, tokenizer, data, max_length=2048):\n",
        "    \"\"\"Calculate perplexity using custom loss function\"\"\"\n",
        "    model.eval()\n",
        "    data_size = len(data)\n",
        "    instructions = [get_prompt(x[\"instruction\"]) for x in data]\n",
        "    outputs = [x[\"output\"] for x in data]\n",
        "\n",
        "    # Tokenize data\n",
        "    tokenized_instructions = tokenizer(instructions, add_special_tokens=False)\n",
        "    tokenized_outputs = tokenizer(outputs, add_special_tokens=False)\n",
        "    output_masks = []\n",
        "\n",
        "    # Format data\n",
        "    for i in range(data_size):\n",
        "        instruction_input_ids = [tokenizer.bos_token_id] + tokenized_instructions[\"input_ids\"][i]\n",
        "        output_input_ids = tokenized_outputs[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
        "        tokenized_instructions[\"input_ids\"][i] = instruction_input_ids + output_input_ids\n",
        "        tokenized_instructions[\"attention_mask\"][i] = [1] * len(tokenized_instructions[\"input_ids\"][i])\n",
        "        output_mask = [0] * len(instruction_input_ids) + [1] * len(output_input_ids)\n",
        "\n",
        "        tokenized_instructions[\"input_ids\"][i] = torch.tensor(\n",
        "            tokenized_instructions[\"input_ids\"][i][:max_length]\n",
        "        ).to(model.device)\n",
        "        tokenized_instructions[\"attention_mask\"][i] = torch.tensor(\n",
        "            tokenized_instructions[\"attention_mask\"][i][:max_length]\n",
        "        ).to(model.device)\n",
        "        output_mask = torch.tensor(output_mask[:max_length]).to(model.device)\n",
        "        output_masks.append(output_mask)\n",
        "\n",
        "    # Calculate ppl\n",
        "    ppls = []\n",
        "    loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "    for i in tqdm(range(data_size), desc=\"Calculating perplexity\"):\n",
        "        input_ids = tokenized_instructions[\"input_ids\"][i].unsqueeze(0)\n",
        "        attn_mask = tokenized_instructions[\"attention_mask\"][i].unsqueeze(0)\n",
        "        output_mask = output_masks[i].unsqueeze(0)\n",
        "        label = input_ids\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out_logits = model(input_ids, attention_mask=attn_mask).logits\n",
        "\n",
        "        shift_logits = out_logits[..., :-1, :].contiguous()\n",
        "        shift_label = label[..., 1:].contiguous()\n",
        "        shift_output_mask = output_mask[..., 1:].contiguous()\n",
        "\n",
        "        perplexity_batch = torch.exp(\n",
        "            (loss_fct(shift_logits.transpose(1, 2), shift_label) * shift_output_mask).sum(1)\n",
        "            / shift_output_mask.sum(1)\n",
        "        )\n",
        "        ppls += perplexity_batch.tolist()\n",
        "\n",
        "    return {\"perplexities\": ppls, \"mean_perplexity\": np.mean(ppls)}\n",
        "\n",
        "def compute_metrics(eval_pred) -> Dict[str, float]:\n",
        "    \"\"\"Compute metrics for trainer evaluation\"\"\"\n",
        "    # We don't use the eval_pred argument since we need the full model\n",
        "    # for proper perplexity calculation. The actual computation is done\n",
        "    # in the PerplexityCallback.\n",
        "    return {}\n"
      ],
      "metadata": {
        "id": "jcr9z0cDqYqz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_and_tokenizer():\n",
        "    \"\"\"Initialize the model and tokenizer with proper configurations\"\"\"\n",
        "    model_name = \"zake7749/gemma-2-2b-it-chinese-kyara-dpo\"\n",
        "\n",
        "    # Initialize tokenizer\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    tokenizer.padding_side = 'right'\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Initialize model with quantization\n",
        "    device_map = { \"\": torch.cuda.current_device() }\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=get_bnb_config(),\n",
        "        device_map=device_map,\n",
        "    )\n",
        "    model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "    # Configure LoRA\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,  # Rank\n",
        "        lora_alpha=32,  # Alpha scaling\n",
        "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Attention modules\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "0DkN_4SCqgW3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.current_device()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJWN6UiNHWI5",
        "outputId": "491efd97-9ea3-4bae-8bee-f064b5359181"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer"
      ],
      "metadata": {
        "id": "qoxQVG5ltMTC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CC4FoZRlqPkc"
      },
      "outputs": [],
      "source": [
        "class PerplexityCallback(TrainerCallback):\n",
        "    \"\"\"Custom callback to log perplexity metrics during training\"\"\"\n",
        "    def __init__(self, eval_dataset, tokenizer):\n",
        "        self.eval_dataset = eval_dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.best_ppl = float('inf')\n",
        "        self.metrics_history = []\n",
        "\n",
        "    def on_evaluate(self, args, state, control, model, **kwargs):\n",
        "        \"\"\"Calculate and log perplexity after each evaluation step\"\"\"\n",
        "\n",
        "\n",
        "        # # Save metrics history\n",
        "        # with open(os.path.join(args.output_dir, \"metrics_history.json\"), \"w\") as f:\n",
        "        #     json.dump(self.metrics_history, f, indent=2)\n",
        "\n",
        "class CustomSFTTrainer(SFTTrainer):\n",
        "    \"\"\"Custom SFTTrainer with integrated perplexity evaluation\"\"\"\n",
        "    def __init__(self, *args, eval_dataset=None, raw_eval_dataset=None, tokenizer=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.eval_dataset = eval_dataset\n",
        "        self.raw_eval_dataset = raw_eval_dataset\n",
        "        self.perplexity_callback = PerplexityCallback(raw_eval_dataset, tokenizer)\n",
        "        self.add_callback(self.perplexity_callback)\n",
        "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
        "        # Call the default evaluation method first\n",
        "        metrics = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
        "        eval_data = [\n",
        "            {\"instruction\": item[\"instruction\"], \"output\": item[\"output\"]}\n",
        "            for item in self.raw_eval_dataset\n",
        "        ]\n",
        "        results = calculate_perplexity(self.model, self.tokenizer, eval_data)\n",
        "        mean_ppl = results[\"mean_perplexity\"]\n",
        "        metrics[\"perplexity\"] = mean_ppl\n",
        "\n",
        "        self.log({f\"{metric_key_prefix}_perplexity\": mean_ppl})\n",
        "        self.log({f\"train_perplexity\": mean_ppl})\n",
        "        print(f\"perplexity:\", mean_ppl)\n",
        "\n",
        "        return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "wuFu_084tUgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = create_model_and_tokenizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "e6953115c740468a807a2ebd6202bcd0",
            "4a7bbe21910f4db7ad18eaf478df683e",
            "ee4e500405974589ad3a5dc7730f09bd",
            "65970e82662a4fdba258ff4e1572f956",
            "9403329896e34170a95d02c999a7799d",
            "c56d22303aac4459a3d45638fd5b539e",
            "19e188516bff40fc84f8054c5bd4f09b",
            "2cf72a90ef0644148cc18c68b5754523",
            "273440244e744f0f8043875777a0ef30",
            "f9fda4bbe2384ff290a4f603951c3146",
            "e770d84b158e4af5a189447505395f38"
          ]
        },
        "id": "V-M2zYPGqjQQ",
        "outputId": "fcee2342-48e8-4587-b75c-17ac97a5563b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Unused kwargs: ['bnb_4bit_fp32_cpu_offload']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6953115c740468a807a2ebd6202bcd0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(examples):\n",
        "    \"\"\"Format the dataset entries into prompt-completion pairs\"\"\"\n",
        "    prompts = [get_prompt(ex) for ex in examples[\"instruction\"]]\n",
        "    texts = [f\"{p}{ex}\" for p, ex in zip(prompts, examples[\"output\"])]\n",
        "    tokenized = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=MAX_SEQ_LENGTH,\n",
        "        return_tensors=None  # Return list of dict instead of tensors\n",
        "    )\n",
        "    print(tokenized)\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "def format_dataset_with_masking(examples):\n",
        "    \"\"\"Format the dataset entries into input_ids and labels for fine-tuning.\"\"\"\n",
        "    prompts = [get_prompt(ex) for ex in examples[\"instruction\"]]\n",
        "\n",
        "    instruction_ids = [\n",
        "        [tokenizer.bos_token_id] + tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
        "        for prompt in prompts\n",
        "    ]\n",
        "    output_ids = [\n",
        "        tokenizer(output, add_special_tokens=False)[\"input_ids\"] + [tokenizer.eos_token_id]\n",
        "        for output in examples[\"output\"]\n",
        "    ]\n",
        "\n",
        "    combined_ids = [instr_ids + out_ids for instr_ids, out_ids in zip(instruction_ids, output_ids)]\n",
        "\n",
        "    # masking for labels\n",
        "    labels = [\n",
        "        [-100] * len(instr_ids) + out_ids for instr_ids, out_ids in zip(instruction_ids, output_ids)\n",
        "    ]\n",
        "    # padding for labels\n",
        "    labels = [\n",
        "        label + [-100] * (MAX_SEQ_LENGTH - len(label)) if len(label) < MAX_SEQ_LENGTH else label[:MAX_SEQ_LENGTH]\n",
        "        for label in labels\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": combined_ids,\n",
        "        \"labels\": labels\n",
        "    }\n",
        "\n",
        "def format_dataset_with_masking_and_attention(examples):\n",
        "    \"\"\"\n",
        "    Format the dataset entries into input_ids and labels for fine-tuning.\n",
        "    Applies proper masking to ensure loss is only calculated on the output tokens.\n",
        "\n",
        "    Args:\n",
        "        examples: Dictionary containing 'instruction' and 'output' keys\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with 'input_ids' and 'labels' for training\n",
        "    \"\"\"\n",
        "    # Tokenize instructions with BOS token\n",
        "    prompts = [get_prompt(ex) for ex in examples[\"instruction\"]]\n",
        "    instruction_ids = [\n",
        "        [tokenizer.bos_token_id] + tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
        "        for prompt in prompts\n",
        "    ]\n",
        "\n",
        "    # Tokenize outputs with EOS token\n",
        "    output_ids = [\n",
        "        tokenizer(output, add_special_tokens=False)[\"input_ids\"] + [tokenizer.eos_token_id]\n",
        "        for output in examples[\"output\"]\n",
        "    ]\n",
        "\n",
        "    # Combine input_ids and handle padding\n",
        "    combined_ids = [instr_ids + out_ids for instr_ids, out_ids in zip(instruction_ids, output_ids)]\n",
        "    combined_ids = [\n",
        "        ids + [tokenizer.pad_token_id] * (MAX_SEQ_LENGTH - len(ids))\n",
        "        if len(ids) < MAX_SEQ_LENGTH\n",
        "        else ids[:MAX_SEQ_LENGTH]\n",
        "        for ids in combined_ids\n",
        "    ]\n",
        "\n",
        "    # Create labels with masking and padding\n",
        "    labels = [\n",
        "        [-100] * len(instr_ids) + out_ids\n",
        "        for instr_ids, out_ids in zip(instruction_ids, output_ids)\n",
        "    ]\n",
        "    labels = [\n",
        "        label + [-100] * (MAX_SEQ_LENGTH - len(label))\n",
        "        if len(label) < MAX_SEQ_LENGTH\n",
        "        else label[:MAX_SEQ_LENGTH]\n",
        "        for label in labels\n",
        "    ]\n",
        "\n",
        "    # Create attention masks\n",
        "    attention_masks = [\n",
        "        [1] * len(ids) + [0] * (MAX_SEQ_LENGTH - len(ids))\n",
        "        if len(ids) < MAX_SEQ_LENGTH\n",
        "        else [1] * MAX_SEQ_LENGTH\n",
        "        for ids in combined_ids\n",
        "    ]\n",
        "\n",
        "    # Verify lengths match\n",
        "    for i in range(len(combined_ids)):\n",
        "        assert len(combined_ids[i]) == len(labels[i]) == len(attention_masks[i]) == MAX_SEQ_LENGTH, \\\n",
        "            f\"Length mismatch: input_ids={len(combined_ids[i])}, labels={len(labels[i])}, mask={len(attention_masks[i])}\"\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": combined_ids,\n",
        "        \"labels\": labels,\n",
        "        \"attention_mask\": attention_masks\n",
        "    }"
      ],
      "metadata": {
        "id": "qiQU-8tEe1se"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_train = train_dataset.map(\n",
        "    format_dataset_with_masking_and_attention,\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset.column_names\n",
        ")\n",
        "formatted_test = test_dataset.map(\n",
        "    format_dataset_with_masking_and_attention,\n",
        "    batched=True,\n",
        "    remove_columns=test_dataset.column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e318cfd8c033407f9acd0bfb4735634c",
            "5b732a0fa8bb4941993fa6872980ccc2",
            "6a8e6e51a8e14752ae9c10c949b5cdc3",
            "081283381bf94c3588032c4f943b3ac5",
            "90f2600e6072424dbbda59e69ca524c1",
            "5de04d88f01f4bf5ae7d76e66d6009a3",
            "d7980117ad8641be9bdee30ff1f66244",
            "df26c6a8e68a46b7a1672e90273b31b2",
            "1d72cd9d0a3346768c50c259f70f6f6c",
            "c97a66cb504d4bd8a886d83c3b6647d2",
            "2977e8f55d054354842848de7835a415",
            "a2bb6828e14c41e2b3c7c98bdda32df9",
            "ee1a57e8f46d4d6293f0d9a9beed6c12",
            "58afc1d0099d475d8ca975296d103d9b",
            "cc517be727cd456ba729abc7effb9e4a",
            "86301b999fd94f30a9933ce73d83ca0f",
            "2d1f4c8aeaeb49a4965bc54798fb301c",
            "5ff9ee768b814ac9a020b05e34b204e5",
            "990ae092c16e489b9b4dc9d26a9a68cf",
            "bc187beb461f4bdcbadac273b6b58e5b",
            "0cadff8c4fd047a0954299ac7587ef72",
            "11ec5f74868445db970ea1d4c353afcd"
          ]
        },
        "id": "cRaYVQVGtSBp",
        "outputId": "362034ed-1102-4ba0-9694-e2eb34dfeef4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e318cfd8c033407f9acd0bfb4735634c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2bb6828e14c41e2b3c7c98bdda32df9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in formatted_train:\n",
        "    print(item)\n",
        "    print(len(item['input_ids']))\n",
        "    break"
      ],
      "metadata": {
        "id": "voRza0NCdkXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9629df5-88d7-422e-bcdd-1e28fe7488ce"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [2, 235608, 203100, 236329, 235767, 236194, 235811, 50039, 235370, 204032, 237938, 235618, 235362, 235918, 181016, 204032, 23541, 235365, 28319, 61755, 239359, 92267, 236132, 140800, 235362, 108, 14053, 235292, 115009, 237568, 242365, 237861, 235597, 236478, 235465, 184433, 235648, 235473, 236421, 112948, 242051, 235716, 235365, 235608, 246747, 238742, 242051, 236538, 235365, 21017, 236111, 236478, 64785, 235997, 235362, 204032, 235636, 235642, 235904, 235642, 235465, 108, 222412, 6100, 235292, 237363, 237568, 237861, 239249, 235465, 235248, 238505, 252830, 236434, 236421, 235822, 235365, 239284, 246747, 242051, 236538, 235365, 235811, 237417, 235461, 235966, 235904, 235362, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 237363, 237568, 237861, 239249, 235465, 235248, 238505, 252830, 236434, 236421, 235822, 235365, 239284, 246747, 242051, 236538, 235365, 235811, 237417, 235461, 235966, 235904, 235362, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Jr_KF1U2d7O"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in test_dataset:\n",
        "    print(item)\n",
        "    print(item)\n",
        "    break\n",
        "for item in formatted_test:\n",
        "    print(item)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHPSjs2Q7192",
        "outputId": "8a0deb04-fcd2-4292-f6f8-be4e0cd4ac36"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '2fb7d211-978f-41c8-a3ab-e51d9df06280', 'instruction': '於是，廢帝讓瀋慶之的堂侄、直將軍瀋攸之賜瀋慶之毒藥，命瀋慶之自殺。翻譯成文言文：', 'output': '帝乃使慶之從父兄子直閣將軍攸之賜慶之藥。', 'task': '翻譯成文言文'}\n",
            "{'id': '2fb7d211-978f-41c8-a3ab-e51d9df06280', 'instruction': '於是，廢帝讓瀋慶之的堂侄、直將軍瀋攸之賜瀋慶之毒藥，命瀋慶之自殺。翻譯成文言文：', 'output': '帝乃使慶之從父兄子直閣將軍攸之賜慶之藥。', 'task': '翻譯成文言文'}\n",
            "{'input_ids': [2, 235608, 203100, 236329, 235767, 236194, 235811, 50039, 235370, 204032, 237938, 235618, 235362, 235918, 181016, 204032, 23541, 235365, 28319, 61755, 239359, 92267, 236132, 140800, 235362, 108, 14053, 235292, 235248, 126459, 235365, 240553, 237008, 237296, 247489, 238979, 235653, 235370, 236815, 242698, 235394, 235948, 189038, 247489, 244242, 235653, 241111, 247489, 238979, 235653, 237334, 239051, 235365, 236313, 247489, 238979, 235653, 193424, 235362, 204032, 235636, 235642, 235904, 235642, 235465, 108, 222412, 6100, 235292, 237008, 237991, 235755, 238979, 235653, 237322, 236701, 237525, 235535, 235948, 239530, 189038, 244242, 235653, 241111, 238979, 235653, 239051, 235362, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 237008, 237991, 235755, 238979, 235653, 237322, 236701, 237525, 235535, 235948, 239530, 189038, 244242, 235653, 241111, 238979, 235653, 239051, 235362, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    return f\"Trainable model parameters: {trainable_params}\\nAll model parameters: {all_param}\\nPercentage of trainable model parameters: {100 * trainable_params / all_param:.2f}%\"\n",
        "\n",
        "print(print_trainable_parameters(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGSn1zzmDim5",
        "outputId": "7acf1a88-e2dd-4e14-80c2-594de855ffe2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable model parameters: 3194880\n",
            "All model parameters: 1605398784\n",
            "Percentage of trainable model parameters: 0.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"chinese_translation_model\"\n",
        "\n",
        "LOG_STEPS = 10\n",
        "\n",
        "# Create training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=32,\n",
        "    learning_rate=3e-4,\n",
        "    max_grad_norm=0.4,\n",
        "    eval_steps=LOG_STEPS,\n",
        "    save_steps=50,\n",
        "    logging_steps=LOG_STEPS,\n",
        "    fp16=True,\n",
        "    tf32=True,\n",
        "    # bp16=True,\n",
        "    save_strategy=\"steps\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    warmup_ratio=0.03,\n",
        "    weight_decay=0.02,\n",
        "    max_steps=400,\n",
        "    load_best_model_at_end=True,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    greater_is_better=False,\n",
        "    gradient_checkpointing=True,\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "# Initialize trainer with custom evaluation\n",
        "trainer = CustomSFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=formatted_train,\n",
        "    eval_dataset=formatted_test,\n",
        "    raw_eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    # dataset_text_field=\"text\",\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47THFttWq5xX",
        "outputId": "55adaeb2-a4e0-4773-c5a3-c20f9be7185a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()  # Frees up unallocated memory"
      ],
      "metadata": {
        "id": "BnWVYuBvH5pz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UtIv8-Bcq-a6",
        "outputId": "43878ae3-d738-40f7-af24-bcdca2e8c87a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mruby0322\u001b[0m (\u001b[33mruby0322-national-taiwan-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241110_054205-gezr7sfj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ruby0322-national-taiwan-university/huggingface/runs/gezr7sfj' target=\"_blank\">chinese_translation_model</a></strong> to <a href='https://wandb.ai/ruby0322-national-taiwan-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ruby0322-national-taiwan-university/huggingface' target=\"_blank\">https://wandb.ai/ruby0322-national-taiwan-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ruby0322-national-taiwan-university/huggingface/runs/gezr7sfj' target=\"_blank\">https://wandb.ai/ruby0322-national-taiwan-university/huggingface/runs/gezr7sfj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 2:47:55, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>4.394100</td>\n",
              "      <td>0.686094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.504100</td>\n",
              "      <td>0.431008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.414700</td>\n",
              "      <td>0.401891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.387300</td>\n",
              "      <td>0.379896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.376200</td>\n",
              "      <td>0.371198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.366700</td>\n",
              "      <td>0.365911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.364400</td>\n",
              "      <td>0.363345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.361400</td>\n",
              "      <td>0.360922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.358900</td>\n",
              "      <td>0.358241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.352700</td>\n",
              "      <td>0.354853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.352100</td>\n",
              "      <td>0.353245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.359300</td>\n",
              "      <td>0.351200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.344000</td>\n",
              "      <td>0.351715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.355300</td>\n",
              "      <td>0.348599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.355500</td>\n",
              "      <td>0.347430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.354200</td>\n",
              "      <td>0.346485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.346500</td>\n",
              "      <td>0.348048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.333400</td>\n",
              "      <td>0.346099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.334100</td>\n",
              "      <td>0.343917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.343300</td>\n",
              "      <td>0.342778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.343500</td>\n",
              "      <td>0.342193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.339400</td>\n",
              "      <td>0.341184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.345700</td>\n",
              "      <td>0.340606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.336700</td>\n",
              "      <td>0.341739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.323800</td>\n",
              "      <td>0.341464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.338100</td>\n",
              "      <td>0.339238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.333500</td>\n",
              "      <td>0.340463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.332800</td>\n",
              "      <td>0.341303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.330700</td>\n",
              "      <td>0.339676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.339700</td>\n",
              "      <td>0.339088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.331200</td>\n",
              "      <td>0.339299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.325200</td>\n",
              "      <td>0.338525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.325800</td>\n",
              "      <td>0.339141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.315200</td>\n",
              "      <td>0.339207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.327500</td>\n",
              "      <td>0.338275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.319100</td>\n",
              "      <td>0.338696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.330100</td>\n",
              "      <td>0.338774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.332000</td>\n",
              "      <td>0.338355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.320100</td>\n",
              "      <td>0.338073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.314900</td>\n",
              "      <td>0.337942</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity:   0%|          | 0/20 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 81.16077134609222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 27.30590078830719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 25.463362395763397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 25.81434211730957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 24.909466552734376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 23.275531858205795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 21.40688602924347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 21.788471114635467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 20.542650026082992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 19.26263724565506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 19.73383839726448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 18.674848473072053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 20.261848157644273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 19.041208803653717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 20.680968099832533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 19.173552811145782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 18.119714826345444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 17.827914279699325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 16.915142464637757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 18.730205327272415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 16.568819332122803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 16.17318880558014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 17.907288694381712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 17.848120391368866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 19.849804669618607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 16.9929045855999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 16.550563418865202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 17.017216908931733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 15.871825677156448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 15.841205149888992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 15.96219236254692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 16.00205546617508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 16.6025308072567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 16.168438690900803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 16.089733123779297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 15.994008129835128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 15.900015193223954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 16.01348750591278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 15.82367542386055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 20/20 [00:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 15.83280103802681\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=400, training_loss=0.44907969772815703, metrics={'train_runtime': 10104.0075, 'train_samples_per_second': 5.067, 'train_steps_per_second': 0.04, 'total_flos': 3.189316415127552e+17, 'train_loss': 0.44907969772815703, 'epoch': 5.12})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model.save_pretrained(os.path.join(output_dir, \"final_checkpoint\"))\n",
        "print(f\"\\nBest Perplexity: {trainer.perplexity_callback.best_ppl:.3f}\")"
      ],
      "metadata": {
        "id": "3gSnvJYzq_rP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf42023-8ac8-4540-c766-281ae7a1224e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Perplexity: inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1v55KH4lmNZqb-Hl2vQTdGq5o6AsvrjKS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MerIOL3fXI3I",
        "outputId": "80b47cb1-284d-41dd-8221-80c718c3742f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1v55KH4lmNZqb-Hl2vQTdGq5o6AsvrjKS\n",
            "To: /content/no-preprocess-zero-shot-15.13.zip\n",
            "100% 23.2M/23.2M [00:00<00:00, 35.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip no-preprocess-zero-shot-15.13.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxOKGvm7Xsi1",
        "outputId": "fed8ffe1-8e02-4cc4-dbfc-85dcd4b95bf0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  no-preprocess-zero-shot-15.13.zip\n",
            "   creating: no-preprocess-zero-shot-15.13/\n",
            "  inflating: __MACOSX/._no-preprocess-zero-shot-15.13  \n",
            "  inflating: no-preprocess-zero-shot-15.13/adapter_model.safetensors  \n",
            "  inflating: __MACOSX/no-preprocess-zero-shot-15.13/._adapter_model.safetensors  \n",
            "  inflating: no-preprocess-zero-shot-15.13/rng_state.pth  \n",
            "  inflating: __MACOSX/no-preprocess-zero-shot-15.13/._rng_state.pth  \n",
            "  inflating: no-preprocess-zero-shot-15.13/tokenizer_config.json  \n",
            "  inflating: __MACOSX/no-preprocess-zero-shot-15.13/._tokenizer_config.json  \n",
            "  inflating: no-preprocess-zero-shot-15.13/special_tokens_map.json  \n",
            "  inflating: __MACOSX/no-preprocess-zero-shot-15.13/._special_tokens_map.json  \n",
            "  inflating: no-preprocess-zero-shot-15.13/optimizer.pt  \n",
            "  inflating: __MACOSX/no-preprocess-zero-shot-15.13/._optimizer.pt  \n",
            "  inflating: no-preprocess-zero-shot-15.13/scheduler.pt  \n",
            "  inflating: __MACOSX/no-preprocess-zero-shot-15.13/._scheduler.pt  \n",
            "  inflating: no-preprocess-zero-shot-15.13/tokenizer.json  \n",
            "  inflating: __MACOSX/no-preprocess-zero-shot-15.13/._tokenizer.json  \n",
            "  inflating: no-preprocess-zero-shot-15.13/README.md  \n",
            "  inflating: __MACOSX/no-preprocess-zero-shot-15.13/._README.md  \n",
            "  inflating: no-preprocess-zero-shot-15.13/training_args.bin  \n",
            "  inflating: __MACOSX/no-preprocess-zero-shot-15.13/._training_args.bin  \n",
            "  inflating: no-preprocess-zero-shot-15.13/adapter_config.json  \n",
            "  inflating: __MACOSX/no-preprocess-zero-shot-15.13/._adapter_config.json  \n",
            "  inflating: no-preprocess-zero-shot-15.13/trainer_state.json  \n",
            "  inflating: __MACOSX/no-preprocess-zero-shot-15.13/._trainer_state.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ./hw3/ppl.py \\\n",
        "    --base_model_path zake7749/gemma-2-2b-it-chinese-kyara-dpo \\\n",
        "    --peft_path ./no-preprocess-zero-shot-15.13 \\\n",
        "    --test_data_path ./data/public_test.json"
      ],
      "metadata": {
        "id": "MXcTyoTxg_Sw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8eea42-8b38-4d24-ee42-8edf99a3dc60"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unused kwargs: ['bnb_4bit_fp32_cpu_offload']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Loading checkpoint shards: 100% 3/3 [00:03<00:00,  1.13s/it]\n",
            "  0% 0/250 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "2024-11-10 09:21:18.227428: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-10 09:21:18.247161: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-10 09:21:18.252542: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-10 09:21:19.426268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "100% 250/250 [01:44<00:00,  2.39it/s]\n",
            "Mean perplexity: 15.135885370731353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./csie5431-applied-data-learning/hw3/inference.py \\\n",
        "    --peft_model_path \"./no-preprocess-zero-shot-15.13\" \\\n",
        "    --input_file \"./data/public_test.json\" \\\n",
        "    --output_file \"./prediction.json\" \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qt0E33_cfYs",
        "outputId": "c15e4826-f0e9-4ef6-ffe6-d08c3a9ce0ad"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer from zake7749/gemma-2-2b-it-chinese-kyara-dpo...\n",
            "Loading base model from zake7749/gemma-2-2b-it-chinese-kyara-dpo...\n",
            "Unused kwargs: ['bnb_4bit_fp32_cpu_offload']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "Loading checkpoint shards: 100% 3/3 [00:03<00:00,  1.06s/it]\n",
            "Loading PEFT model from ./no-preprocess-zero-shot-15.13...\n",
            "Reading test data from ./data/public_test.json...\n",
            "Generating predictions...\n",
            "  0% 0/250 [00:00<?, ?it/s]The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "2024-11-10 09:48:56.704435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-10 09:48:56.722530: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-10 09:48:56.727854: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-10 09:48:57.902064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "100% 250/250 [17:54<00:00,  4.30s/it]\n",
            "Saving predictions to ./prediction.json...\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}